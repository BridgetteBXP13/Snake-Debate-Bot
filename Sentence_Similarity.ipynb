{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing Sentence Similarity**\n",
        "\n",
        "With typical models so far for the chatbot the input dataset has heavily struggled as it is a very small dataset and there are many different ways to write a sentence. This causes the accuracy to be very low as well as the fact that there are about 50 different categories (classes) and only about 350 entries. My goal is to test if a sentence is similar to a sentence in the dataset rather than directly predicting the category."
      ],
      "metadata": {
        "id": "iPbKxOAdfBNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model\n",
        "\n",
        "For this I found the model all-MiniML-L6-v2 as it is the most popular and recently updated. I tested it with a few inputs and seemed to do fairly well with my intended use for the chatbot in their summary on huggingface.com. Here is a link to the model:\n",
        "\n",
        "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
        "\n",
        "I also used this guide to help create my model using Tensorflow:\n",
        "\n",
        "https://www.philschmid.de/tensorflow-sentence-transformers"
      ],
      "metadata": {
        "id": "9IT2SA4Lfz45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up My Environment\n",
        "\n",
        "First I have to install transformers and sentence transformers as a prerequisite for the model."
      ],
      "metadata": {
        "id": "56ekiGccgUCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[tf] -q --upgrade\n",
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR1gXyVieeqr",
        "outputId": "202809e2-c1b8-4f02-f53f-dc9167345976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.5 MB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 42.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 44.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 442 kB 59.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 39.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 46.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 35.6 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "\n",
        "Here my data is in a csv file with text inputs correlating to a catgorey. In this case we only care about the possible text inputs in the dataset, as we are going to compare direct user inputs to our input data to check for similarity.\n",
        "\n",
        "This dataset can be found here:\n",
        "https://github.com/BridgetteBXP13/CS-4395.001---Human-Language-Technologies/blob/main/Chatbot/Data/Inputs.csv"
      ],
      "metadata": {
        "id": "q-PwiIBqjQF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing pandas\n",
        "import pandas as pd\n",
        "# Import our data\n",
        "url = 'https://raw.githubusercontent.com/BridgetteBXP13/CS-4395.001---Human-Language-Technologies/main/Chatbot/Data/Inputs.csv'\n",
        "df = pd.read_csv(url)\n",
        "print(\"\\nOur loaded dataframe:\\n\")\n",
        "df.head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrldC0aejO7w",
        "outputId": "0e770026-abeb-4da9-eb3a-f9ceb84da8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Our loaded dataframe:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                  Input        Category\n",
              "0                                Snakes are aggressive        Behavior\n",
              "1                                 Are they aggressive         Behavior\n",
              "2    Snakes will not bite unless you try to approac...        Behavior\n",
              "3                              Do snakes like to bite?        Behavior\n",
              "4                                  Snakes chase people        Behavior\n",
              "..                                                 ...             ...\n",
              "325                             Snakes are emotionless           Brain\n",
              "326                               Can snakes grow hair            Body\n",
              "327                                    Snakes are mean        Behavior\n",
              "328                            Why should snakes exist  Snake Benefits\n",
              "329                                Are snakes any good  Snake Benefits\n",
              "\n",
              "[330 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the first column into a list of strings for Tensorflow\n",
        "inputs = []   # Our empty list\n",
        "# A for loop to traverse through each observation of the 'Inputs' column\n",
        "for input in df.Input:\n",
        "  inputs.append(input)\n",
        "print(\"\\nOur first five inputs in our new list:\\n\")\n",
        "print(inputs[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee3m1LwqnZ6Q",
        "outputId": "1dc744cb-2541-4f1b-851e-5e736ae6e3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Our first five inputs in our new list:\n",
            "\n",
            "['Snakes are aggressive', 'Are they aggressive ', 'Snakes will not bite unless you try to approach/handle them.', 'Do snakes like to bite?', 'Snakes chase people']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create TensorFlow Model\n",
        "\n",
        "Here I heavily used the guide mentioned above as the instructions on HuggingFace were PyTorch based and I wanted to use TensorFlow and Keras for this project. In these steps we will create a compatible model in order to utilize the pretrained model."
      ],
      "metadata": {
        "id": "LVLQPC3Agtc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "class TFSentenceTransformer(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_name_or_path, **kwargs):\n",
        "        super(TFSentenceTransformer, self).__init__()\n",
        "        # loads transformers model\n",
        "        self.model = TFAutoModel.from_pretrained(model_name_or_path, **kwargs)\n",
        "\n",
        "    def call(self, inputs, normalize=True):\n",
        "        # runs model on inputs\n",
        "        model_output = self.model(inputs)\n",
        "        # Perform pooling. In this case, mean pooling.\n",
        "        embeddings = self.mean_pooling(model_output, inputs[\"attention_mask\"])\n",
        "        # normalizes the embeddings if wanted\n",
        "        if normalize:\n",
        "          embeddings = self.normalize(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
        "        input_mask_expanded = tf.cast(\n",
        "            tf.broadcast_to(tf.expand_dims(attention_mask, -1), tf.shape(token_embeddings)),\n",
        "            tf.float32\n",
        "        )\n",
        "        return tf.math.reduce_sum(token_embeddings * input_mask_expanded, axis=1) / tf.clip_by_value(tf.math.reduce_sum(input_mask_expanded, axis=1), 1e-9, tf.float32.max)\n",
        "\n",
        "    def normalize(self, embeddings):\n",
        "      embeddings, _ = tf.linalg.normalize(embeddings, 2, axis=1)\n",
        "      return embeddings"
      ],
      "metadata": {
        "id": "PPdcsppHhXc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = TFSentenceTransformer(model_id)\n",
        "\n",
        "# Run inference & create embeddings\n",
        "encoded_input = tokenizer(inputs[:12], padding=True, truncation=True, return_tensors='tf')\n",
        "sentence_embedding = model(encoded_input)\n",
        "print(\"\\nOur Embedded Sentence Tensorflow Shape:\\n\")\n",
        "print(sentence_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5GGWPQqiH4T",
        "outputId": "bbc619c9-cecb-47f0-fc1c-20eb013e8721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Our Embedded Sentence Tensorflow Shape:\n",
            "\n",
            "(12, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Inference and Testing Results\n",
        "\n",
        "Here I will test the comparisons with some inputs to see how well it is at testing similarity"
      ],
      "metadata": {
        "id": "03M7Bojjpw-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "compare_inputs = [\"Whales love me\", \"Taxes are very high\", \"I lost my phone today\", \n",
        "                  \"Snakes can't breathe\", \"Snakes like people\", \"Snakes always bite people\",\n",
        "                  \"Snakes lay eggs\", \"What snakes are venomous?\"]\n",
        "\n",
        "# loading sentence transformers\n",
        "st_model = SentenceTransformer(model_id,device=\"cpu\")\n",
        "for compare_input in compare_inputs:\n",
        "  # run inference with sentence transformers\n",
        "  st_embeddings = st_model.encode(compare_input)\n",
        "  # run inference with TFSentenceTransformer\n",
        "  encoded_input = tokenizer(compare_input, return_tensors=\"tf\")\n",
        "  tf_embeddings =  model(encoded_input)\n",
        "\n",
        "  # compare embeddings\n",
        "  are_results_close = np.allclose(tf_embeddings.numpy()[0],st_embeddings, rtol=1e-30, atol=1e-07)\n",
        "  print(\"Comparing: \", compare_input)\n",
        "  print(f\"Results close: {are_results_close}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG7zgA5mqUFD",
        "outputId": "fae2854f-6230-45c0-ef6e-bf146e7be1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing:  Whales love me\n",
            "Results close: False\n",
            "Comparing:  Taxes are very high\n",
            "Results close: False\n",
            "Comparing:  I lost my phone today\n",
            "Results close: False\n",
            "Comparing:  Snakes can't breathe\n",
            "Results close: False\n",
            "Comparing:  Snakes like people\n",
            "Results close: True\n",
            "Comparing:  Snakes always bite people\n",
            "Results close: True\n",
            "Comparing:  Snakes lay eggs\n",
            "Results close: False\n",
            "Comparing:  What snakes are venomous?\n",
            "Results close: True\n"
          ]
        }
      ]
    }
  ]
}